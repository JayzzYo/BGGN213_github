---
title: "Class07 Machine Learning 1"
author: "Zixuan Zeng (A16142927)"
format: pdf
toc: true
---

Today we will begin our exploration of some "classical" machine learning approaches. We will start will clustering:

Let's first make up some data to cluster where we know what the answer should be.

```{r}
hist( rnorm(1000) )
```

```{r}
x <- c(rnorm(30,mean=-3), rnorm(30,mean=3))
y <- rev(x)

x <- cbind(x,y)
head(x)
```

plot x

```{r}
plot(x)
```

The main function in "base" R for K-means clustering is called `kmeas()`.

```{r}
k <- kmeans(x, centers=2)
k
```
>Q. How big are the clusters (i.e. their size)?

```{r}
k$size
```

>Q. What clusters do my data points reside in?

```{r}
k$cluster
```

>Q. Make a plot of our data colored by cluster assignment(i.e. make a result figure)

```{r}
plot(x,col=k$cluster)
points(k$centers,col="blue",pch=15)
```

>Q. Cluster with k-means into 4 clustrs and plot your results as above.

```{r}
k4 <- kmeans(x, centers=4)
plot(x,col=k4$cluster)
points(k4$centers,col="blue",pch=15)
```


>Q. Run kmeans with center (i.e. values of k) equal 1 to 6

```{r}
k1 <- kmeans(x, centers=1)$tot.withinss
k2 <- kmeans(x, centers=2)$tot.withinss
k3 <- kmeans(x, centers=3)$tot.withinss
k4 <- kmeans(x, centers=4)$tot.withinss
k5 <- kmeans(x, centers=5)$tot.withinss
k6 <- kmeans(x, centers=6)$tot.withinss

ans <- c(k1,k2,k3,k4,k5,k6)
```

Or use a `for` loop

```{r}
ans <- NULL
for(i in 1:6){
  km <- kmeans(x, centers=i)
  ans[i] <- km$tot.withinss
}
ans
```

Make a "screen-plot"

```{r}
plot(ans,typ="b")
```

## Hierarchical Clustering

The main function in "base" R for this is called `hclust()`.

```{r}
d <- dist(x)
hc <- hclust(d)
hc
plot(hc)
abline(h=7,col="red")
```

To obtain clusters from our `hclust` result object **hc**, we cut the tree to yield different sub branches
For this we use the `cutree()` function.

```{r}
grps <- cutree(hc,h=7)
grps
```

```{r}
plot(x,col=grps)
```

## PCA

```{r}
url <- "https://tinyurl.com/UK-foods"
x <- read.csv(url)
```

>Q1. 17 rows and 5 column dim(x)

>Q2. I like the first approach as the code feels more straight-forward to me. Running it more than one time could remove the informatin we want.

>Q3. beside = FALSE

```{r}
rownames(x) <- x[,1]
x <- x[,-1]
head(x)
barplot(as.matrix(x), beside=T, col=rainbow(nrow(x)))
```

```{r}
barplot(as.matrix(x), beside=FALSE, col=rainbow(nrow(x)))
```

>Q4. Delete the position = "dodge" argument

```{r}
library(tidyr)
library(ggplot2)
x_long <- x |> 
          tibble::rownames_to_column("Food") |> 
          pivot_longer(cols = -Food, 
                       names_to = "Country", 
                       values_to = "Consumption")
ggplot(x_long) +
  aes(x = Country, y = Consumption, fill = Food) +
  geom_col() +
  theme_bw()
```


>Q5. Plots above and below each diagonal countries are replicates. Each plot represents compairson between the two countries vertical to the plot. Each dot represents a food item. The position of the dot represents the consumption amount in each country. The dot would be on the diagonal of the plot if two countries consum about the same amount of that particular food. 

```{r}
pairs(x, col=rainbow(nrow(x)), pch=16)
```


```{r}
library(pheatmap)
pheatmap( as.matrix(x) )
```

>Q6. Scotland, England, and Wales are clustered together in contrast to N.Ireland. This result indicates that N.Ireland has a different food consumption pattern than the other three countries. Main differences are a little hard to spot since the color is not that different. 


## PCA to the rescue

The main function in "base" R for PCA is called `prcomp()`.

As we want to do a PCA on the food data for the different countries, we will want the foods in the columns.

```{r}
PCA <- prcomp(t(x))
summary(PCA)
```

Our result object is called `PCA` and it has a `$x` component that we will look at first.

```{r}
PCA$x
ggplot(PCA$x) + aes(PC1,PC2) + geom_point()
```


>Q7. The finished code is below. 

```{r}
# Create a data frame for plotting
df <- as.data.frame(PCA$x)
df$Country <- rownames(df)

# Plot PC1 vs PC2 with ggplot
ggplot(PCA$x) +
  aes(x = PC1, y = PC2, label = rownames(PCA$x)) +
  geom_point(size = 3) +
  geom_text(vjust = -0.5) +
  xlim(-270, 500) +
  xlab("PC1") +
  ylab("PC2") +
  theme_bw()
```


>Q8.

```{r}
ggplot(PCA$x) +
  aes(x = PC1, y = PC2, label = rownames(PCA$x)) +
  geom_point(size = 3,color=c('orange', 'red', 'blue', 'darkgreen'), pch = 1) +
  geom_text(vjust = -0.5) +
  xlim(-270, 500) +
  xlab("PC1") +
  ylab("PC2") +
  theme_bw()
```


Another major result out of PCA is the so-called "variable loadings" or `$rotation` that tells us how the original variables (foods) contribute to PCs. 


```{r}
ggplot(PCA$rotation) +
  aes(x = PC1, 
      y = reorder(rownames(PCA$rotation), PC1)) +
  geom_col(fill = "steelblue") +
  xlab("PC1 Loading Score") +
  ylab("") +
  theme_bw() +
  theme(axis.text.y = element_text(size = 9))
```


>Q9. Soft drinks and alcoholic drinks feature prominently in PC2. PC2 mainly tells us that consumption of soft and alcoholic drinks separates Scotland from the cluster that contains the rest of three countries. 

```{r}
ggplot(PCA$rotation) +
  aes(x = PC2, 
      y = reorder(rownames(PCA$rotation), PC2)) +
  geom_col(fill = "red") +
  xlab("PC2 Loading Score") +
  ylab("") +
  theme_bw() +
  theme(axis.text.y = element_text(size = 9))
```

## RNA-seq data exploration

>Q10. 100 genes and 10 samples

```{r}
url2 <- "https://tinyurl.com/expression-CSV"
rna.data <- read.csv(url2, row.names=1)
head(rna.data)
dim(rna.data)
```


```{r}
## Again we have to take the transpose of our data 
pca <- prcomp(t(rna.data), scale=TRUE)

# Create data frame for plotting
df <- as.data.frame(pca$x)
df$Sample <- rownames(df)

## Plot with ggplot
ggplot(df) +
  aes(x = PC1, y = PC2, label = Sample) +
  geom_point(size = 3) +
  geom_text(vjust = -0.5, size = 3) +
  xlab("PC1") +
  ylab("PC2") +
  theme_bw() 

summary(pca)

# Calculate variance explained
pca.var <- pca$sdev^2
pca.var.per <- round(pca.var/sum(pca.var)*100, 1)

# Create scree plot data
scree_df <- data.frame(
  PC = factor(paste0("PC", 1:10), levels = paste0("PC", 1:10)),
  Variance = pca.var[1:10]
)

ggplot(scree_df) +
  aes(x = PC, y = Variance) +
  geom_col(fill = "steelblue") +
  ggtitle("Quick scree plot") +
  xlab("Principal Component") +
  ylab("Variance") +
  theme_bw()

```


```{r}
pca.var.per

# Create percent variance scree plot
scree_pct_df <- data.frame(
  PC = factor(paste0("PC", 1:10), levels = paste0("PC", 1:10)),
  PercentVariation = pca.var.per[1:10]
)

ggplot(scree_pct_df) +
  aes(x = PC, y = PercentVariation) +
  geom_col(fill = "steelblue") +
  ggtitle("Scree Plot") +
  xlab("Principal Component") +
  ylab("Percent Variation") +
  theme_bw()
```


```{r}
## A vector of colors for wt and ko samples
colvec <- colnames(rna.data)
colvec[grep("wt", colvec)] <- "red"
colvec[grep("ko", colvec)] <- "blue"

# Add condition to data frame
df$condition <- substr(df$Sample, 1, 2)
df$color <- colvec

ggplot(df) +
  aes(x = PC1, y = PC2, color = color, label = Sample) +
  geom_point(size = 3) +
  geom_text(vjust = -0.5, hjust = 0.5, show.legend = FALSE) +
  scale_color_identity() +
  xlab(paste0("PC1 (", pca.var.per[1], "%)")) +
  ylab(paste0("PC2 (", pca.var.per[2], "%)")) +
  theme_bw()
```


```{r}
loading_scores <- pca$rotation[,1]

## Find the top 10 measurements (genes) that contribute
## most to PC1 in either direction (+ or -)
gene_scores <- abs(loading_scores) 
gene_score_ranked <- sort(gene_scores, decreasing=TRUE)

## show the names of the top 10 genes
top_10_genes <- names(gene_score_ranked[1:10])
top_10_genes 
```

```{r}
ggplot(pca$rotation) +
  aes(x = PC1, 
      y = reorder(rownames(pca$rotation), PC1)) +
  geom_col(fill = "steelblue") +
  xlab("PC1 Loading Score") +
  ylab("") +
  theme_bw() +
  theme(axis.text.y = element_text(size = 9))
```

